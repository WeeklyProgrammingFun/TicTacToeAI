{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToeDataset(Dataset):\n",
    "    def __init__(self,filename):\n",
    "        # list of 9 tuples, each a board state: 0=blank,1=X, -1=O\n",
    "        #samples = [] \n",
    "        # list of good replies, 0 = bad, 1 = good\n",
    "        #truth   = [] \n",
    "        \n",
    "        self.data = torch.from_numpy(\n",
    "            np.genfromtxt(filename, delimiter=\",\",dtype=np.float32)\n",
    "            ) \n",
    "        print(self.data)#.shape())\n",
    "        print(self.data.size()[0])\n",
    "    def __len__(self):\n",
    "        return self.data.size()[0]\n",
    "    def __getitem__(self,index):\n",
    "        d = self.data[index]\n",
    "        sample = {'state' : d[0:9], 'moves': d[9:18] }\n",
    "        return sample\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0.,  ...,  1.,  1., nan],\n",
      "        [ 1.,  0.,  0.,  ...,  0.,  0., nan],\n",
      "        [ 0.,  1.,  0.,  ...,  1.,  0., nan],\n",
      "        ...,\n",
      "        [ 0., -1., -1.,  ...,  0.,  0., nan],\n",
      "        [ 0., -1., -1.,  ...,  0.,  0., nan],\n",
      "        [ 0., -1., -1.,  ...,  0.,  0., nan]])\n",
      "4520\n"
     ]
    }
   ],
   "source": [
    "fn = 'TicTacToeData.txt'\n",
    "ds = ToeDataset(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'moves': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'moves': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AI_1, self).__init__()\n",
    "        \n",
    "        # 2 corners, 350 size internals works\n",
    "        # 2 corners, 275 size internals fails\n",
    "        \n",
    "        board_size = 9\n",
    "        internal1  = 350 # big enough to memorize 4500ish entries\n",
    "        self.net   = nn.Sequential(\n",
    "            nn.Linear(board_size, internal1),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(internal1, internal1),\n",
    "            \n",
    "            #nn.ReLU(),\n",
    "            \n",
    "            #nn.Linear(internal1, internal1),\n",
    "            \n",
    "            #nn.ReLU(),\n",
    "\n",
    "            #nn.Linear(internal1, internal1),\n",
    "            \n",
    "            nn.ReLU(),            \n",
    "\n",
    "            nn.Linear(internal1, board_size)                      \n",
    "            );\n",
    "    def forward(self, in_data):\n",
    "        x = self.net(in_data)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AI_1(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=9, out_features=275, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=275, out_features=275, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=275, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = AI_1()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Get the cuda device\n",
    "print(device)\n",
    "net1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    net = AI_1().to(device)\n",
    "    fn = 'TicTacToeData.txt'\n",
    "    dataset = ToeDataset(fn)\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size = 300)\n",
    "    \n",
    "    loss_func = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "    \n",
    "    for epoch in range(500):\n",
    "        dataiter = iter(loader)\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in dataiter:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            out = net(batch['state'].to(device))\n",
    "            \n",
    "            loss = loss_func(out, batch['moves'].to(device))\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            loss.backward()            \n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "        print(epoch_loss)\n",
    "        \n",
    "        \n",
    "    sample = dataset[100]\n",
    "    print(sample)\n",
    "    out1 = net(sample['state'].to(device))\n",
    "    print(out1)\n",
    "    return net\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0.,  ...,  1.,  1., nan],\n",
      "        [ 1.,  0.,  0.,  ...,  0.,  0., nan],\n",
      "        [ 0.,  1.,  0.,  ...,  1.,  0., nan],\n",
      "        ...,\n",
      "        [ 0., -1., -1.,  ...,  0.,  0., nan],\n",
      "        [ 0., -1., -1.,  ...,  0.,  0., nan],\n",
      "        [ 0., -1., -1.,  ...,  0.,  0., nan]])\n",
      "4520\n",
      "2.6572772562503815\n",
      "2.0336792543530464\n",
      "1.5916908457875252\n",
      "1.3439830765128136\n",
      "1.2631757333874702\n",
      "1.227058857679367\n",
      "1.1710941717028618\n",
      "1.142081007361412\n",
      "1.1275925636291504\n",
      "1.0943470522761345\n",
      "1.0763061046600342\n",
      "1.0504592061042786\n",
      "1.0477298460900784\n",
      "1.0035236775875092\n",
      "1.0057264678180218\n",
      "0.9792597219347954\n",
      "0.9769995994865894\n",
      "0.9576794803142548\n",
      "0.9488920159637928\n",
      "0.9296834208071232\n",
      "0.9325046837329865\n",
      "0.9145033992826939\n",
      "0.8954276740550995\n",
      "0.8979905061423779\n",
      "0.8807524368166924\n",
      "0.8664508834481239\n",
      "0.8576922379434109\n",
      "0.8553134053945541\n",
      "0.8708939179778099\n",
      "0.8340794593095779\n",
      "0.8169158659875393\n",
      "0.8296901285648346\n",
      "0.8074702173471451\n",
      "0.8117688372731209\n",
      "0.7834704518318176\n",
      "0.7921396531164646\n",
      "0.8166643008589745\n",
      "0.7790522389113903\n",
      "0.768589124083519\n",
      "0.7672018483281136\n",
      "0.7526136040687561\n",
      "0.739798478782177\n",
      "0.7473834082484245\n",
      "0.7447649091482162\n",
      "0.7407396472990513\n",
      "0.7160784490406513\n",
      "0.7201848924160004\n",
      "0.7192853540182114\n",
      "0.7285311259329319\n",
      "0.7335160486400127\n",
      "0.7069519646465778\n",
      "0.6928981132805347\n",
      "0.6846366189420223\n",
      "0.6777874268591404\n",
      "0.6765634082257748\n",
      "0.6801711991429329\n",
      "0.666241966187954\n",
      "0.6774085275828838\n",
      "0.6618689112365246\n",
      "0.6590344086289406\n",
      "0.655865453183651\n",
      "0.659080546349287\n",
      "0.6623612008988857\n",
      "0.6526135914027691\n",
      "0.6366495527327061\n",
      "0.6348550021648407\n",
      "0.6307628788053989\n",
      "0.624084148555994\n",
      "0.6094961911439896\n",
      "0.6184671744704247\n",
      "0.618509616702795\n",
      "0.6146015785634518\n",
      "0.5959846265614033\n",
      "0.596819443628192\n",
      "0.5814993549138308\n",
      "0.5797998197376728\n",
      "0.5961283817887306\n",
      "0.5895427204668522\n",
      "0.5778134800493717\n",
      "0.5636514592915773\n",
      "0.5440299585461617\n",
      "0.5582361407577991\n",
      "0.5573987476527691\n",
      "0.5632479004561901\n",
      "0.5639381352812052\n",
      "0.5699286945164204\n",
      "0.5486751273274422\n",
      "0.5355152897536755\n",
      "0.5525570251047611\n",
      "0.5335648525506258\n",
      "0.5392495319247246\n",
      "0.5465725269168615\n",
      "0.5330373514443636\n",
      "0.5304956994950771\n",
      "0.5150441061705351\n",
      "0.5116908438503742\n",
      "0.5196006577461958\n",
      "0.5191679559648037\n",
      "0.5151590034365654\n",
      "0.5148689169436693\n",
      "0.5192445535212755\n",
      "0.5053221918642521\n",
      "0.5026003643870354\n",
      "0.493850851431489\n",
      "0.48093358986079693\n",
      "0.4801785349845886\n",
      "0.48389025032520294\n",
      "0.49741416797041893\n",
      "0.486454164609313\n",
      "0.4798761401325464\n",
      "0.46601006761193275\n",
      "0.4666810464113951\n",
      "0.46933589316904545\n",
      "0.4681826550513506\n",
      "0.4689885042607784\n",
      "0.46924217604100704\n",
      "0.46943201310932636\n",
      "0.47065732441842556\n",
      "0.44722128100693226\n",
      "0.45910059101879597\n",
      "0.4583899546414614\n",
      "0.4546093549579382\n",
      "0.4382510110735893\n",
      "0.42482721246778965\n",
      "0.43641403317451477\n",
      "0.4417998604476452\n",
      "0.44297439232468605\n",
      "0.43826125375926495\n",
      "0.4397219270467758\n",
      "0.43792534805834293\n",
      "0.4380992390215397\n",
      "0.4225861970335245\n",
      "0.4199721980839968\n",
      "0.4016052056103945\n",
      "0.4082903563976288\n",
      "0.40922624059021473\n",
      "0.3992094602435827\n",
      "0.410277983173728\n",
      "0.4105995763093233\n",
      "0.41740335524082184\n",
      "0.4141848385334015\n",
      "0.40694599226117134\n",
      "0.4077052753418684\n",
      "0.39490223303437233\n",
      "0.4021362643688917\n",
      "0.40514315105974674\n",
      "0.41576457396149635\n",
      "0.38956754468381405\n",
      "0.3816786427050829\n",
      "0.3838968761265278\n",
      "0.3772099819034338\n",
      "0.37999408692121506\n",
      "0.3768892642110586\n",
      "0.36489309929311275\n",
      "0.3667120784521103\n",
      "0.3730103336274624\n",
      "0.37485786341130733\n",
      "0.37884265929460526\n",
      "0.369884604588151\n",
      "0.3639271315187216\n",
      "0.36238694190979004\n",
      "0.3583485186100006\n",
      "0.36055539548397064\n",
      "0.36271028220653534\n",
      "0.35434627812355757\n",
      "0.3549193274229765\n",
      "0.3569164592772722\n",
      "0.3477741200476885\n",
      "0.34945010021328926\n",
      "0.3520814888179302\n",
      "0.3451958168298006\n",
      "0.3401527889072895\n",
      "0.3506667297333479\n",
      "0.3411343786865473\n",
      "0.3346241470426321\n",
      "0.3441820256412029\n",
      "0.3405518215149641\n",
      "0.332845326513052\n",
      "0.3272180203348398\n",
      "0.3209835682064295\n",
      "0.3235059082508087\n",
      "0.32456669211387634\n",
      "0.3336662333458662\n",
      "0.3276845645159483\n",
      "0.32084745541214943\n",
      "0.3252652045339346\n",
      "0.3144630193710327\n",
      "0.31506271846592426\n",
      "0.30942440778017044\n",
      "0.30578205175697803\n",
      "0.3086307691410184\n",
      "0.29985490534454584\n",
      "0.31162869185209274\n",
      "0.3112277649343014\n",
      "0.31225810945034027\n",
      "0.3025420792400837\n",
      "0.30373336654156446\n",
      "0.3009476363658905\n",
      "0.28920444659888744\n",
      "0.306518679484725\n",
      "0.30177037604153156\n",
      "0.30693650990724564\n",
      "0.31772032752633095\n",
      "0.2955497857183218\n",
      "0.29647708125412464\n",
      "0.2801052387803793\n",
      "0.2828948060050607\n",
      "0.28381406888365746\n",
      "0.28644002974033356\n",
      "0.2971028368920088\n",
      "0.2822705116122961\n",
      "0.29758612252771854\n",
      "0.27822099532932043\n",
      "0.2821536585688591\n",
      "0.2786879315972328\n",
      "0.27392601035535336\n",
      "0.27305026911199093\n",
      "0.27067642007023096\n",
      "0.27062204759567976\n",
      "0.27453686855733395\n",
      "0.27579579688608646\n",
      "0.27388797234743834\n",
      "0.2705319756641984\n",
      "0.2622899478301406\n",
      "0.2627575071528554\n",
      "0.26366650126874447\n",
      "0.26827018428593874\n",
      "0.26940377429127693\n",
      "0.27598727867007256\n",
      "0.27548870351165533\n",
      "0.2739335121586919\n",
      "0.2673722021281719\n",
      "0.256355207413435\n",
      "0.2555675823241472\n",
      "0.2535551227629185\n",
      "0.25405966117978096\n",
      "0.25658833142369986\n",
      "0.25278315879404545\n",
      "0.24602077063173056\n",
      "0.2666795225813985\n",
      "0.24103588797152042\n",
      "0.24425305053591728\n",
      "0.2512741480022669\n",
      "0.24980155751109123\n",
      "0.23329858295619488\n",
      "0.23818673472851515\n",
      "0.2530207196250558\n",
      "0.25086663383990526\n",
      "0.2459001112729311\n",
      "0.2360407980158925\n",
      "0.23947205860167742\n",
      "0.2455599969252944\n",
      "0.24434787966310978\n",
      "0.24250106047838926\n",
      "0.23275747429579496\n",
      "0.2334540393203497\n",
      "0.23202190920710564\n",
      "0.23432612605392933\n",
      "0.24459316954016685\n",
      "0.24695214070379734\n",
      "0.2343835635110736\n",
      "0.22398539166897535\n",
      "0.22312864754348993\n",
      "0.23234209511429071\n",
      "0.22637535259127617\n",
      "0.2270691990852356\n",
      "0.22121900878846645\n",
      "0.2244704393669963\n",
      "0.2252973234280944\n",
      "0.2203676961362362\n",
      "0.21849249862134457\n",
      "0.21901020035147667\n",
      "0.2185234520584345\n",
      "0.22770032566040754\n",
      "0.22276821825653315\n",
      "0.21159298811107874\n",
      "0.21651987917721272\n",
      "0.2146791685372591\n",
      "0.21722465194761753\n",
      "0.21740512177348137\n",
      "0.210109980776906\n",
      "0.21072335168719292\n",
      "0.2106392588466406\n",
      "0.20506094582378864\n",
      "0.20831016451120377\n",
      "0.20942430570721626\n",
      "0.2120225727558136\n",
      "0.208634365350008\n",
      "0.20164327695965767\n",
      "0.19760113209486008\n",
      "0.20801715645939112\n",
      "0.20360346883535385\n",
      "0.20491481106728315\n",
      "0.19766009785234928\n",
      "0.19492516387254\n",
      "0.20052045490592718\n",
      "0.20947576686739922\n",
      "0.21033035591244698\n",
      "0.19366723392158747\n",
      "0.194688661955297\n",
      "0.19204632472246885\n",
      "0.19346162863075733\n",
      "0.19657669495791197\n",
      "0.19570833910256624\n",
      "0.196759513579309\n",
      "0.19102431740611792\n",
      "0.19072286877781153\n",
      "0.189524638466537\n",
      "0.18677218724042177\n",
      "0.1820855950936675\n",
      "0.17562408279627562\n",
      "0.19025511760264635\n",
      "0.19829958770424128\n",
      "0.18644762318581343\n",
      "0.18329472467303276\n",
      "0.1816620845347643\n",
      "0.1811814894899726\n",
      "0.1864827862009406\n",
      "0.1878531090915203\n",
      "0.1907248916104436\n",
      "0.18141482211649418\n",
      "0.18679242860525846\n",
      "0.18674273323267698\n",
      "0.180868630297482\n",
      "0.172026751562953\n",
      "0.17163742892444134\n",
      "0.1717425361275673\n",
      "0.1697580711916089\n",
      "0.17573068477213383\n",
      "0.1748357256874442\n",
      "0.16751528158783913\n",
      "0.16713353991508484\n",
      "0.17199753317981958\n",
      "0.1708825882524252\n",
      "0.16958803217858076\n",
      "0.16560272965580225\n",
      "0.16497634164988995\n",
      "0.16002478636801243\n",
      "0.15829094965010881\n",
      "0.16235924698412418\n",
      "0.16642009746283293\n",
      "0.17300725635141134\n",
      "0.17566339392215014\n",
      "0.16634186077862978\n",
      "0.1760462997481227\n",
      "0.18674154672771692\n",
      "0.19255715981125832\n",
      "0.17057147435843945\n",
      "0.1635283725336194\n",
      "0.1586345098912716\n",
      "0.16177234333008528\n",
      "0.1622397224418819\n",
      "0.16155196446925402\n",
      "0.166493758559227\n",
      "0.1655751457437873\n",
      "0.15604468900710344\n",
      "0.1536750653758645\n",
      "0.15422045486047864\n",
      "0.15809084847569466\n",
      "0.15824934747070074\n",
      "0.158585537225008\n",
      "0.1574248494580388\n",
      "0.16043278109282255\n",
      "0.16558249108493328\n",
      "0.16044860146939754\n",
      "0.15608027298003435\n",
      "0.1548306429758668\n",
      "0.16263676388189197\n",
      "0.15325158648192883\n",
      "0.15216296538710594\n",
      "0.1568056456744671\n",
      "0.14800963550806046\n",
      "0.15000695455819368\n",
      "0.1490884618833661\n",
      "0.1527348030358553\n",
      "0.15242796577513218\n",
      "0.1513612475246191\n",
      "0.1441881856881082\n",
      "0.1495041400194168\n",
      "0.15223984327167273\n",
      "0.14718390069901943\n",
      "0.14815173111855984\n",
      "0.1462352923117578\n",
      "0.14360215328633785\n",
      "0.1462535336613655\n",
      "0.14341838285326958\n",
      "0.14289124682545662\n",
      "0.1440460979938507\n",
      "0.1498519629240036\n",
      "0.1512575768865645\n",
      "0.14390236884355545\n",
      "0.13813068205490708\n",
      "0.1419990872964263\n",
      "0.1408039703965187\n",
      "0.14043303299695253\n",
      "0.1376031581312418\n",
      "0.14167553931474686\n",
      "0.14427029341459274\n",
      "0.1398356962017715\n",
      "0.1419155653566122\n",
      "0.1368780303746462\n",
      "0.1305132661946118\n",
      "0.13102878304198384\n",
      "0.13618708029389381\n",
      "0.13312968984246254\n",
      "0.13378701219335198\n",
      "0.13819898571819067\n",
      "0.13646491570398211\n",
      "0.13126651337370276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13180328719317913\n",
      "0.13316433504223824\n",
      "0.1374906892888248\n",
      "0.13544325390830636\n",
      "0.12743340153247118\n",
      "0.13217527931556106\n",
      "0.14093870483338833\n",
      "0.136001733597368\n",
      "0.14042984321713448\n",
      "0.12575004529207945\n",
      "0.1285915533080697\n",
      "0.12867113901302218\n",
      "0.1280670785345137\n",
      "0.13176402868703008\n",
      "0.12734649423509836\n",
      "0.1234326851554215\n",
      "0.12473432160913944\n",
      "0.12591570895165205\n",
      "0.12325229356065392\n",
      "0.12271815445274115\n",
      "0.12616942403838038\n",
      "0.13327718852087855\n",
      "0.13193385861814022\n",
      "0.1256871186196804\n",
      "0.12333728326484561\n",
      "0.12219238700345159\n",
      "0.11902703391388059\n",
      "0.12046280689537525\n",
      "0.11590688349679112\n",
      "0.11349154636263847\n",
      "0.12154862098395824\n",
      "0.12054250668734312\n",
      "0.11608629627153277\n",
      "0.12089894618839025\n",
      "0.11247481312602758\n",
      "0.1138797695748508\n",
      "0.12818618351593614\n",
      "0.12282279739156365\n",
      "0.11655153939500451\n",
      "0.11368130566552281\n",
      "0.11344160651788116\n",
      "0.12226659944280982\n",
      "0.12598552973940969\n",
      "0.12385676568374038\n",
      "0.12374743819236755\n",
      "0.12261227145791054\n",
      "0.11977852834388614\n",
      "0.11113854078575969\n",
      "0.11641282588243484\n",
      "0.11586029315367341\n",
      "0.11504087690263987\n",
      "0.1224644728936255\n",
      "0.12060090759769082\n",
      "0.11409967113286257\n",
      "0.11045197630301118\n",
      "0.11033873585984111\n",
      "0.10709452722221613\n",
      "0.10804799199104309\n",
      "0.11216572066769004\n",
      "0.1086316010914743\n",
      "0.10990318935364485\n",
      "0.10806077159941196\n",
      "0.10641783801838756\n",
      "0.109281986951828\n",
      "0.11008909624069929\n",
      "0.1149515095166862\n",
      "0.10873125633224845\n",
      "0.10573004931211472\n",
      "0.11094963969662786\n",
      "0.10884238453581929\n",
      "0.11151796253398061\n",
      "0.10423524444922805\n",
      "0.10370157472789288\n",
      "0.1048594368621707\n",
      "0.10912647796794772\n",
      "0.1060699475929141\n",
      "0.1086912821047008\n",
      "0.10590285155922174\n",
      "0.09938681405037642\n",
      "0.10268869297578931\n",
      "0.10373458126559854\n",
      "0.10867864452302456\n",
      "0.10064514353871346\n",
      "0.10280332015827298\n",
      "0.10232117166742682\n",
      "0.10480361431837082\n",
      "0.10378550598397851\n",
      "0.10811203112825751\n",
      "0.10356220742687583\n",
      "0.11010914156213403\n",
      "0.10499853966757655\n",
      "{'state': tensor([ 1.,  0.,  0., -1.,  0.,  0.,  1.,  0.,  0.]), 'moves': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0.])}\n",
      "tensor([-0.0045, -0.0280, -0.0113,  0.0467,  1.0485, -0.0086, -0.0763,  0.0294,\n",
      "         0.1699], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0283,  0.0993, -0.0317,  0.0339,  0.8389, -0.0849,  0.1238,  0.0043,\n",
       "         0.1151], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = torch.FloatTensor([1,0,0,0,0,0,0,0,0]).to(device)\n",
    "net.forward(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': tensor([ 1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  1.]),\n",
       " 'moves': tensor([0., 1., 1., 1., 1., 1., 0., 1., 0.])}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeOne(index):\n",
    "    test1 = torch.FloatTensor(ds[index]['state']).to(device)\n",
    "    return net.forward(test1)\n",
    "    \n",
    "def drawOne(index):\n",
    "    test1 = torch.FloatTensor(ds[index]['state']).to(device)\n",
    "    print(net.forward(test1) - torch.FloatTensor(ds[index]['moves']).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0134, -0.0064,  0.0010, -0.0042,  0.0050, -0.0175,  0.0240,  0.0243,\n",
      "         0.0065], device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "drawOne(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(index):\n",
    "    # turn vector into 0,1 best guesses\n",
    "    vec = computeOne(index)\n",
    "    #vec = torch.FloatTensor([1,0,0,0,0,0,0,0,0]).to(device)\n",
    "    #vec = net.forward(vec)\n",
    "    max = torch.max(vec).item()\n",
    "    min = torch.min(vec).item()\n",
    "    # cleaned = (vec-min)/(max-min) > 0.5\n",
    "    cleaned = vec > 0.5\n",
    "    cc = cleaned.float()\n",
    "    return cc\n",
    "    # print(max,min,vec,cleaned,cc)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ds[1234]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': tensor([ 1.,  0., -1.,  0.,  1., -1.,  1.,  0.,  0.]),\n",
       " 'moves': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1.])}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all match truth\n",
    "# todo - rewrite to do all in one pass on GPU\n",
    "def checkAll():\n",
    "    failed = 0\n",
    "    for i in range(len(ds)):\n",
    "        ans = cleaner(i)\n",
    "        truth = ds[i]['moves'].to(device)\n",
    "        diff = torch.max(abs(ans-truth)).item()\n",
    "        if diff > 0:\n",
    "            print(i,ans,truth,diff)\n",
    "            failed = failed + 1\n",
    "    print('failed:',failed)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed: 0\n"
     ]
    }
   ],
   "source": [
    "checkAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "computeOne(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0168, -0.0028,  0.9695,  0.2486,  0.9427,  0.0703,  0.1640,  0.0597,\n",
       "         0.9497], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeOne(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
